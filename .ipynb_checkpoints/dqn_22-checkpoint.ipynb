{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "from GameEnv import Game2048\n",
    "from DQN import DQN\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "def check_one_game(gameEnv,debug):\n",
    "    gameEnv.reset()\n",
    "    flag = False\n",
    "    observation = copy.deepcopy(gameEnv.matrix)\n",
    "    while True:\n",
    "        if debug:gameEnv.display()\n",
    "        if flag:\n",
    "            action = random.choice([\"a\",\"w\",\"d\",\"s\"])\n",
    "            if debug:print(\"random:\",action)\n",
    "        else:\n",
    "            action = RL.choose_action_max([observation])\n",
    "            if debug:print(\"choose:\",action)\n",
    "        observation_, reward, done = gameEnv.step(action)\n",
    "        flag = True if observation_ == observation else False\n",
    "        observation = copy.deepcopy(observation_)\n",
    "        if debug:print(\"_________________________________________\")\n",
    "        if done:\n",
    "            print(\"this_score_____________________:\",gameEnv.score)\n",
    "            break\n",
    "\n",
    "# 策略迭代测试\n",
    "def check_one_game_with_model(gameEnv,model,debug):\n",
    "    gameEnv.reset()\n",
    "    observation = copy.deepcopy(gameEnv.matrix)\n",
    "    while True:\n",
    "        if debug:gameEnv.display()\n",
    "        probs = model.sess.run(model.predictions, feed_dict={model.matrixInput:np.array([observation])})[0]\n",
    "        res_dict = {i:k for i,k in zip( [\"a\",\"s\",\"w\",\"d\"],probs)}\n",
    "        sort_res = sorted(res_dict.items(),key = lambda x:x[1],reverse = True) \n",
    "        for action,probs in sort_res:\n",
    "            observation_, reward, done = gameEnv.step(action)\n",
    "            if observation_ != observation:\n",
    "                break\n",
    "        if debug:print \"choose:\",action\n",
    "        observation = copy.deepcopy(observation_)\n",
    "        if debug:print(\"_________________________________________\")\n",
    "        if done:\n",
    "            if debug:gameEnv.display()\n",
    "            if debug:print(\"this_score_____________________:\",gameEnv.score)\n",
    "            break\n",
    "    return gameEnv.score\n",
    "\n",
    "def evaluate(gameEnv,model,n=1000):\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        scores.append(check_one_game_with_model(gameEnv,model,False))\n",
    "    print \"--------------------------avg:%d max:%d min:%d e:%f\"%(np.average(scores),np.max(scores), np.min(scores), 0.8 ** (model.step / 1000))\n",
    "    \n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10804721 0.3157593  0.19074932 0.60029596]\n",
      "[-0.24244675 -0.10830572  0.11108035  0.69447464]\n",
      "[0.18583435 1.7801096  1.0066937  4.887335  ]\n",
      "--------------------------avg:29 max:68 min:0 e:1.000000\n",
      "('loss', 100, 2.2345562)\n",
      "('loss', 200, 6.7363133)\n",
      "('loss', 300, 20.386293)\n",
      "[15.190179 11.365096  4.698616 14.680653]\n",
      "[ 4.4990535 13.191273  13.582177   8.757918 ]\n",
      "[ 2.0564947  -0.23796523 -1.9545914   1.747033  ]\n",
      "--------------------------avg:27 max:76 min:4 e:1.000000\n",
      "('loss', 400, 3.3430529)\n",
      "('loss', 500, 6.4669094)\n",
      "('loss', 600, 109.79094)\n",
      "('loss', 700, 1.8649052)\n",
      "[8.342616  4.8294015 4.9321957 6.0976853]\n",
      "[5.436181  7.8484898 8.243881  5.852316 ]\n",
      "[ 0.3206851   1.9003851   1.1705284  -0.03534782]\n",
      "--------------------------avg:21 max:76 min:0 e:1.000000\n",
      "('loss', 800, 2.18609)\n",
      "('loss', 900, 3.777513)\n",
      "('loss', 1000, 3.6722505)\n",
      "('loss', 1100, 6.3311553)\n",
      "[18.365599 17.311787  5.228858 20.066614]\n",
      "[ 8.644829 19.877333 17.834824 19.704027]\n",
      "[ 3.3505     -0.46597505  0.8258521   3.7286208 ]\n",
      "--------------------------avg:29 max:76 min:4 e:0.800000\n",
      "('loss', 1200, 3.0228531)\n",
      "('loss', 1300, 11.989073)\n",
      "('loss', 1400, 6.106821)\n",
      "('loss', 1500, 5.135249)\n",
      "[25.460978  30.126184   5.5030775 27.85792  ]\n",
      "[ 5.9712625 29.814573  27.747793  23.354761 ]\n",
      "[5.6491776 1.2984569 3.494738  2.0457072]\n",
      "--------------------------avg:32 max:140 min:12 e:0.800000\n",
      "('loss', 1600, 6.521532)\n",
      "('loss', 1700, 12.697033)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4c25c9c64d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1000\u001b[0m  \u001b[0;32mand\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mRL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mRL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience_replary_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mprint\u001b[0m  \u001b[0mRL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mRL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrixInput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/opt/jupyter/fanyu.zhang/reinforcement_learning/ReinforcementLearning_2048/DQN.py\u001b[0m in \u001b[0;36mexperience_replary_final\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexperience_replary_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gameEnv = Game2048()\n",
    "gameEnv.grid_n = 2\n",
    "RL = DQN(learning_rate=0.1,sigma=0.1,grid_n = 2,batch_size=1000,file_data=\"train_data_22.csv\",h1=64,h2=32,h3=16)\n",
    "flag = False\n",
    "for episode in range(500000):\n",
    "    # 初始化环境\n",
    "    gameEnv.reset()\n",
    "    observation = copy.deepcopy(gameEnv.matrix)\n",
    "    while True:\n",
    "        # DQN 根据观测值选择行为\n",
    "        if flag:\n",
    "            l = [\"a\",\"w\",\"s\",\"d\"]\n",
    "            l.remove(action)\n",
    "            action = random.choice(l)\n",
    "        else:\n",
    "            action = RL.choose_action([copy.deepcopy(observation)])\n",
    "        # 环境根据行为给出下一个 state, reward, 是否终止\n",
    "        observation_, reward, done = gameEnv.step(action)\n",
    "        # DQN 存储记忆\n",
    "        RL.experience_store(observation, action, reward,done,observation_)\n",
    "        # 控制学习起始时间和频率 (先累积一些记忆再开始学习)\n",
    "    \n",
    "        # 将下一个 state_ 变为 下次循环的 state\n",
    "        observation = copy.deepcopy(observation_)\n",
    "        flag = True if observation_ == observation else False\n",
    "        # 如果终止, 就跳出循环\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    if (episode > 1000  and episode % 50 == 0):\n",
    "        RL.train()\n",
    "        RL.train(RL.experience_replary_final())\n",
    "    if episode % 10000 == 0:\n",
    "        print  RL.sess.run(RL.predictions, feed_dict={RL.matrixInput:np.array([[[2,2],[0,0]]])})[0]\n",
    "        print  RL.sess.run(RL.predictions, feed_dict={RL.matrixInput:np.array([[[2,0],[2,0]]])})[0]\n",
    "        print  RL.sess.run(RL.predictions, feed_dict={RL.matrixInput:np.array([[[16,8],[8,4]]])})[0]\n",
    "        evaluate(gameEnv,RL)\n",
    "#         print \"_\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss', 12100, 87.55404)\n",
      "('loss', 12200, 120.535965)\n",
      "('loss', 12300, 110.53438)\n",
      "('loss', 12400, 105.34289)\n",
      "('loss', 12500, 120.56972)\n",
      "('loss', 12600, 98.28268)\n",
      "('loss', 12700, 90.12865)\n",
      "('loss', 12800, 123.289116)\n",
      "('loss', 12900, 97.51391)\n",
      "('loss', 13000, 132.04372)\n",
      "[71.59496  69.03806  -0.387748 66.02849 ]\n",
      "[ 1.5428932 70.86559   74.53679   71.5933   ]\n",
      "[-3.4322658 -3.2689986  1.6923378 -1.7342143]\n",
      "--------------------------avg:55 max:156 min:12 e:0.054976\n",
      "('loss', 13100, 101.68195)\n",
      "('loss', 13200, 106.01286)\n",
      "('loss', 13300, 147.6299)\n",
      "('loss', 13400, 127.57087)\n",
      "('loss', 13500, 116.67538)\n",
      "('loss', 13600, 102.681595)\n",
      "('loss', 13700, 109.27301)\n",
      "('loss', 13800, 105.513885)\n",
      "('loss', 13900, 96.64741)\n",
      "('loss', 14000, 106.358925)\n",
      "[74.23017   69.790215   1.9300134 72.64188  ]\n",
      "[ 1.8135515 64.24989   70.3606    69.435036 ]\n",
      "[1.3306836  4.2929754  0.45117688 5.093516  ]\n",
      "--------------------------avg:53 max:160 min:12 e:0.043980\n",
      "('loss', 14100, 132.74733)\n",
      "('loss', 14200, 116.6754)\n",
      "('loss', 14300, 124.37045)\n",
      "('loss', 14400, 101.87828)\n",
      "('loss', 14500, 102.85046)\n",
      "('loss', 14600, 111.57053)\n",
      "('loss', 14700, 103.24911)\n",
      "('loss', 14800, 112.36994)\n",
      "('loss', 14900, 135.98935)\n",
      "('loss', 15000, 102.48797)\n",
      "[71.479706  69.85586   -1.8234022 71.96304  ]\n",
      "[-0.43780935 71.75753    73.89575    72.526474  ]\n",
      "[-0.7198943 -2.1738596  1.1617157 -3.698925 ]\n",
      "--------------------------avg:57 max:164 min:12 e:0.035184\n",
      "('loss', 15100, 108.8704)\n",
      "('loss', 15200, 128.52934)\n",
      "('loss', 15300, 112.67864)\n",
      "('loss', 15400, 120.56451)\n",
      "('loss', 15500, 118.62587)\n",
      "('loss', 15600, 143.19896)\n",
      "('loss', 15700, 123.03633)\n",
      "('loss', 15800, 100.091644)\n",
      "('loss', 15900, 103.235794)\n",
      "('loss', 16000, 126.81236)\n",
      "[6.8297333e+01 7.0701027e+01 4.1141510e-02 6.7056465e+01]\n",
      "[ 1.3279151 74.267395  73.378555  72.986824 ]\n",
      "[-2.327651  -1.9489253  2.1883135 -1.7185369]\n",
      "--------------------------avg:56 max:160 min:12 e:0.028147\n",
      "('loss', 16100, 111.38606)\n",
      "('loss', 16200, 100.63764)\n",
      "('loss', 16300, 120.91382)\n",
      "('loss', 16400, 103.73636)\n",
      "('loss', 16500, 125.71578)\n",
      "('loss', 16600, 117.34832)\n",
      "('loss', 16700, 104.00583)\n",
      "('loss', 16800, 108.16458)\n",
      "('loss', 16900, 126.5119)\n",
      "('loss', 17000, 118.948425)\n",
      "[74.85193   69.2621    -1.0699952 65.15294  ]\n",
      "[ 2.2045648 70.736206  69.56194   67.74532  ]\n",
      "[-3.0987215  3.9393318  3.728978  -1.9757156]\n",
      "--------------------------avg:56 max:156 min:12 e:0.022518\n",
      "('loss', 17100, 129.4379)\n",
      "('loss', 17200, 105.95029)\n",
      "('loss', 17300, 93.74829)\n",
      "('loss', 17400, 81.87414)\n",
      "('loss', 17500, 100.79741)\n",
      "('loss', 17600, 118.457565)\n",
      "('loss', 17700, 97.830284)\n",
      "('loss', 17800, 102.91203)\n",
      "('loss', 17900, 114.93583)\n",
      "('loss', 18000, 114.77619)\n",
      "[71.34648   67.192856   1.0297239 72.91638  ]\n",
      "[ 1.5324073 71.824936  70.53469   76.03788  ]\n",
      "[-0.650755   -2.8249202  -4.3186107  -0.02854848]\n",
      "--------------------------avg:55 max:164 min:12 e:0.018014\n",
      "('loss', 18100, 131.13074)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2cf0ec2ad734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mRL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#         RL.train(RL.experience_replary_final())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m  \u001b[0mRL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mRL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrixInput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/opt/jupyter/fanyu.zhang/reinforcement_learning/ReinforcementLearning_2048/DQN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnext_status\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for i in range(1000):\n",
    "        RL.train()\n",
    "#         RL.train(RL.experience_replary_final())\n",
    "    print  RL.sess.run(RL.predictions, feed_dict={RL.matrixInput:np.array([[[2,2],[0,0]]])})[0]\n",
    "    print  RL.sess.run(RL.predictions, feed_dict={RL.matrixInput:np.array([[[2,0],[2,0]]])})[0]\n",
    "    print  RL.sess.run(RL.predictions, feed_dict={RL.matrixInput:np.array([[[16,8],[8,4]]])})[0]\n",
    "    evaluate(gameEnv,RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list([[2, 4], [8, 2]]), 'w', 0, True, list([[2, 4], [8, 2]])],\n",
       "       [list([[8, 4], [4, 8]]), 'a', 0, True, list([[8, 4], [4, 8]])],\n",
       "       [list([[2, 8], [8, 2]]), 'a', 0, True, list([[2, 8], [8, 2]])],\n",
       "       ...,\n",
       "       [list([[8, 4], [4, 2]]), 'a', 0, True, list([[8, 4], [4, 2]])],\n",
       "       [list([[8, 4], [4, 2]]), 'd', 0, True, list([[8, 4], [4, 2]])],\n",
       "       [list([[8, 4], [4, 2]]), 'w', 0, True, list([[8, 4], [4, 2]])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RL.experience_replary_final()\n",
    "# RL.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.516754]\n",
      "['a', 's', 'w', 'd']\n"
     ]
    }
   ],
   "source": [
    "status = [[[2,2],[0,0]]]\n",
    "print RL.sess.run([RL.action_predictions], feed_dict={RL.matrixInput:np.array(status),RL.actionInput:np.array(RL._one_hot([RL.actions_index_dicts[\"d\"]]))})[0]\n",
    "\n",
    "\n",
    "print [\"a\",\"s\",\"w\",\"d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.650217323303224\n"
     ]
    }
   ],
   "source": [
    "sum_ = 0\n",
    "for i in range(100):\n",
    "    a = random.choice([\"a\",\"s\",\"w\",\"d\"])\n",
    "    gameEnv.matrix = [[4,0],[0,2]]\n",
    "    sum_ += np.max(RL.sess.run([RL.predictions], feed_dict={RL.matrixInput:np.array([gameEnv.step(a)[0]])})[0])\n",
    "print sum_ /100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42.738956]\n",
      "[[ 2.4858952  5.5781164  8.688911  42.738956 ]]\n",
      "['a', 's', 'w', 'd']\n"
     ]
    }
   ],
   "source": [
    "status = [[[4,0],[2,0]]]\n",
    "print RL.sess.run([RL.action_predictions], feed_dict={RL.matrixInput:np.array(status),RL.actionInput:np.array(RL._one_hot([RL.actions_index_dicts[\"d\"]]))})[0]\n",
    "print RL.sess.run([RL.predictions], feed_dict={RL.matrixInput:np.array(status),RL.actionInput:np.array(RL._one_hot([RL.actions_index_dicts[\"a\"]]))})[0]\n",
    "\n",
    "print [\"a\",\"s\",\"w\",\"d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07614094]\n",
      "[[ 1.9967844  13.085197   -2.276273    0.07614094]]\n",
      "['a', 's', 'w', 'd']\n",
      "16\t 8\t \n",
      "\n",
      "8\t 4\t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "status = [[[16,8],[8,4]]]\n",
    "print RL.sess.run([RL.action_predictions], feed_dict={RL.matrixInput:np.array(status),RL.actionInput:np.array(RL._one_hot([RL.actions_index_dicts[\"d\"]]))})[0]\n",
    "print RL.sess.run([RL.predictions], feed_dict={RL.matrixInput:np.array(status),RL.actionInput:np.array(RL._one_hot([RL.actions_index_dicts[\"a\"]]))})[0]\n",
    "\n",
    "print [\"a\",\"s\",\"w\",\"d\"]\n",
    "gameEnv.display(status[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6c29d39277e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "data = np.array(RL.memory)\n",
    "data = data[data[:, 3] == True]\n",
    "train_data = np.array([RL.memory[-1]])\n",
    "status = np.array([i for i in train_data[:,0]])\n",
    "action = RL._one_hot([RL.actions_index_dicts[i] for i in train_data[:,1]])\n",
    "reward = train_data[:,2]\n",
    "done = train_data[:,3]\n",
    "next_status = np.array([i for i in train_data[:,4]])\n",
    "\n",
    "\n",
    "# print (reward)\n",
    "# print (action)\n",
    "maxQNext = RL.get_max_availble_action_value(next_status)\n",
    "y = []\n",
    "for i in range(1000):\n",
    "    if done[i] == True:\n",
    "        y.append(reward[i])\n",
    "    else:\n",
    "        y.append(reward[i] + RL.sigma * maxQNext[i])\n",
    "\n",
    "feed_dict = {RL.matrixInput: np.array(status), RL.actionInput: np.array(action),RL.yInput: np.array(y)}\n",
    "\n",
    "# for i in range(2000):\n",
    "#     RL.sess.run([RL.loss,RL.train_op], feed_dict=feed_dict)\n",
    "# print RL.sess.run([RL.loss,RL.train_op], feed_dict=feed_dict)\n",
    "# print RL.sess.run(RL.predictions, feed_dict={RL.matrixInput:np.array([[[8, 4], [4, 8]]])})[0]\n",
    "# self.step = global_step\n",
    "# if global_step % 100 == 0:\n",
    "#     print(\"loss\",global_step,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\t -\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "choose: w\n",
      "_________________________________________\n",
      "2\t 2\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "choose: a\n",
      "_________________________________________\n",
      "4\t 4\t \n",
      "\n",
      "2\t -\t \n",
      "\n",
      "choose: a\n",
      "_________________________________________\n",
      "8\t -\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "choose: d\n",
      "_________________________________________\n",
      "4\t 8\t \n",
      "\n",
      "-\t 4\t \n",
      "\n",
      "choose: s\n",
      "_________________________________________\n",
      "2\t 8\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "choose: d\n",
      "_________________________________________\n",
      "2\t 8\t \n",
      "\n",
      "4\t 8\t \n",
      "\n",
      "choose: s\n",
      "_________________________________________\n",
      "2\t 2\t \n",
      "\n",
      "4\t 16\t \n",
      "\n",
      "choose: a\n",
      "_________________________________________\n",
      "4\t 2\t \n",
      "\n",
      "4\t 16\t \n",
      "\n",
      "choose: s\n",
      "_________________________________________\n",
      "4\t 2\t \n",
      "\n",
      "8\t 16\t \n",
      "\n",
      "choose: w\n",
      "_________________________________________\n",
      "4\t 2\t \n",
      "\n",
      "8\t 16\t \n",
      "\n",
      "('this_score_____________________:', 52)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " check_one_game_with_model(gameEnv,RL,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameEnv.matrix = [[2,4],[2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_one_game_with_model(gameEnv,model,debug):\n",
    "    gameEnv.reset()\n",
    "#     gameEnv.matrix = [[2,2],[0,0]]\n",
    "    observation = copy.deepcopy(gameEnv.matrix)\n",
    "    while True:\n",
    "        if debug:gameEnv.display()\n",
    "        probs = model.sess.run(model.predictions, feed_dict={model.matrixInput:np.array([observation])})[0]\n",
    "        res_dict = {i:k for i,k in zip( [\"a\",\"s\",\"w\",\"d\"],probs)}\n",
    "        sort_res = sorted(res_dict.items(),key = lambda x:x[1],reverse = True) \n",
    "        for action,probs in sort_res:\n",
    "            observation_, reward, done = gameEnv.step(action)\n",
    "            if observation_ != observation or done:\n",
    "                break\n",
    "            print gameEnv.display(),action\n",
    "        if debug:print \"choose:\",action\n",
    "        observation = copy.deepcopy(observation_)\n",
    "        if debug:print(\"_________________________________________\")\n",
    "        if done:\n",
    "            if debug:gameEnv.display()\n",
    "            if debug:print(\"this_score_____________________:\",gameEnv.score)\n",
    "            break\n",
    "    return gameEnv.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\t 2\t \n",
      "\n",
      "2\t -\t \n",
      "\n",
      "choose: s\n",
      "_________________________________________\n",
      "-\t 4\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "choose: a\n",
      "_________________________________________\n",
      "4\t 4\t \n",
      "\n",
      "4\t -\t \n",
      "\n",
      "choose: s\n",
      "_________________________________________\n",
      "4\t -\t \n",
      "\n",
      "8\t 4\t \n",
      "\n",
      "choose: d\n",
      "_________________________________________\n",
      "2\t 4\t \n",
      "\n",
      "8\t 4\t \n",
      "\n",
      "choose: s\n",
      "_________________________________________\n",
      "2\t 2\t \n",
      "\n",
      "8\t 8\t \n",
      "\n",
      "choose: a\n",
      "_________________________________________\n",
      "4\t 4\t \n",
      "\n",
      "16\t -\t \n",
      "\n",
      "choose: d\n",
      "_________________________________________\n",
      "2\t 8\t \n",
      "\n",
      "-\t 16\t \n",
      "\n",
      "choose: a\n",
      "_________________________________________\n",
      "2\t 8\t \n",
      "\n",
      "16\t 4\t \n",
      "\n",
      "choose: a\n",
      "_________________________________________\n",
      "2\t 8\t \n",
      "\n",
      "16\t 4\t \n",
      "\n",
      "('this_score_____________________:', 48)\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print check_one_game_with_model(gameEnv,RL,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss', 23000, 78.130844)\n",
      "[34.42205   -4.1494017  0.5097985 44.897858 ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    RL.train()\n",
    "print  RL.sess.run(RL.predictions, feed_dict={RL.matrixInput:np.array([[[2,2],[8,4]]])})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\t 4\t \n",
      "\n",
      "2\t 32\t \n",
      "\n",
      "None s\n",
      "32\t 8\t \n",
      "\n",
      "-\t 4\t \n",
      "\n",
      "None w\n",
      "8\t 32\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None d\n",
      "8\t 32\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None w\n",
      "4\t 32\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None w\n",
      "-\t 32\t \n",
      "\n",
      "4\t 8\t \n",
      "\n",
      "None s\n",
      "32\t 4\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "4\t -\t \n",
      "\n",
      "None a\n",
      "32\t 4\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None w\n",
      "4\t 4\t \n",
      "\n",
      "32\t 2\t \n",
      "\n",
      "None w\n",
      "8\t 4\t \n",
      "\n",
      "32\t 4\t \n",
      "\n",
      "None a\n",
      "8\t 8\t \n",
      "\n",
      "32\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "4\t -\t \n",
      "\n",
      "None a\n",
      "32\t 4\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None d\n",
      "2\t 2\t \n",
      "\n",
      "8\t 32\t \n",
      "\n",
      "None s\n",
      "2\t 2\t \n",
      "\n",
      "8\t 32\t \n",
      "\n",
      "None w\n",
      "8\t 32\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "None w\n",
      "8\t 32\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "None s\n",
      "8\t 32\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "8\t 32\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None s\n",
      "32\t 2\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "32\t 4\t \n",
      "\n",
      "4\t -\t \n",
      "\n",
      "None a\n",
      "32\t 8\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "32\t 4\t \n",
      "\n",
      "4\t -\t \n",
      "\n",
      "None a\n",
      "32\t 2\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None d\n",
      "-\t 32\t \n",
      "\n",
      "4\t 8\t \n",
      "\n",
      "None s\n",
      "32\t 4\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "32\t 4\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None w\n",
      "4\t 4\t \n",
      "\n",
      "2\t 32\t \n",
      "\n",
      "None s\n",
      "32\t 2\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "32\t 2\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "8\t 32\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None d\n",
      "8\t 32\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 4\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "None w\n",
      "2\t 32\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "-\t 32\t \n",
      "\n",
      "2\t 8\t \n",
      "\n",
      "None s\n",
      "32\t 4\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "32\t 2\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None d\n",
      "32\t 8\t \n",
      "\n",
      "-\t 4\t \n",
      "\n",
      "None w\n",
      "32\t 4\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "32\t 4\t \n",
      "\n",
      "-\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "-\t 4\t \n",
      "\n",
      "None w\n",
      "32\t 4\t \n",
      "\n",
      "4\t -\t \n",
      "\n",
      "None a\n",
      "32\t 8\t \n",
      "\n",
      "2\t 2\t \n",
      "\n",
      "None w\n",
      "32\t 8\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "8\t 32\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n",
      "8\t 32\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None s\n",
      "4\t 4\t \n",
      "\n",
      "2\t 32\t \n",
      "\n",
      "None s\n",
      "32\t 8\t \n",
      "\n",
      "4\t -\t \n",
      "\n",
      "None a\n",
      "32\t 8\t \n",
      "\n",
      "4\t 4\t \n",
      "\n",
      "None w\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5bf922c97a7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgameEnv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-2b8b0b8b0076>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(gameEnv, model, n)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_one_game_with_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgameEnv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"--------------------------avg:%d max:%d min:%d e:%f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-c1a55f13c933>\u001b[0m in \u001b[0;36mcheck_one_game_with_model\u001b[0;34m(gameEnv, model, debug)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgameEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrixInput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mres_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"d\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msort_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;31m# TODO(yuanbyu, keveman): Revisit whether we should just treat feeding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0;31m# of a handle from a different device as an error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m     \u001b[0mfinal_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0mfinal_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_update_with_movers\u001b[0;34m(self, feed_dict, feed_map)\u001b[0m\n\u001b[1;32m   1422\u001b[0m     \u001b[0mhandle_movers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfeed_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m       \u001b[0mmover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_handle_mover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0mhandle_movers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/session_ops.pyc\u001b[0m in \u001b[0;36m_get_handle_mover\u001b[0;34m(graph, feeder, handle)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_handle_mover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0;34m\"\"\"Return a move subgraph for this pair of feeder and handle.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_handle_feeder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/session_ops.pyc\u001b[0m in \u001b[0;36m_get_handle_feeder\u001b[0;34m(graph, feeder)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_handle_feeder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_feeders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeeder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1786\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1788\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_def_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate(gameEnv,RL,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.0471907  8.333307   2.5626736 -4.0253177]\n"
     ]
    }
   ],
   "source": [
    "print  RL.sess.run(RL.predictions, feed_dict={RL.matrixInput:np.array([[[4,4],[2,32]]])})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameEnv.matrix = [[4,4],[2,32]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\t 2\t \n",
      "\n",
      "2\t 32\t \n",
      "\n",
      "8\t 2\t \n",
      "\n",
      "2\t 32\t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gameEnv.display()\n",
    "gameEnv.step(\"d\")\n",
    "gameEnv.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
